# ğŸš€ Projeto: Demo de PadrÃµes de ResiliÃªncia

Este projeto contÃ©m uma aplicaÃ§Ã£o de demonstraÃ§Ã£o prÃ¡tica projetada para ilustrar padrÃµes de resiliÃªncia em sistemas distribuÃ­dos (Timeout, Retry, Backoff e Jitter) para uma audiÃªncia de desenvolvedores de nÃ­vel jÃºnior a pleno.

A demo Ã© totalmente dinÃ¢mica: os estados de falha e lentidÃ£o sÃ£o controlados via API, sem a necessidade de reiniciar ou recriar os serviÃ§os. A visualizaÃ§Ã£o do impacto Ã© feita em tempo real usando Grafana e Prometheus.

---

## ğŸ›ï¸ Arquitetura da DemonstraÃ§Ã£o

A demo Ã© composta pelos seguintes serviÃ§os orquestrados com Docker Compose:

* **`unreliable-provider` (ServiÃ§o InstÃ¡vel):**
    * Um serviÃ§o Spring Boot que expÃµe uma API (`/server/unreliable-endpoint`).
    * Possui uma API de controle (`/control`) que permite ao apresentador tornÃ¡-lo lento ou fazÃª-lo falhar "N" vezes, dinamicamente.
* **`resilient-client` (Cliente Resiliente):**
    * O serviÃ§o Spring Boot principal da demo.
    * Usa **OpenFeign** para chamar o `provider`.
    * Usa **Spring Retry** para implementar as estratÃ©gias de Retry, Backoff e Jitter.
    * ExpÃµe endpoints (`/demo/...`) que acionam cada cenÃ¡rio de resiliÃªncia.
* **Prometheus:**
    * Coleta mÃ©tricas de ambos os serviÃ§os (`client` e `provider`) via Actuator.
* **Grafana:**
    * Visualiza as mÃ©tricas do Prometheus.
    * Sobe com um dashboard prÃ©-configurado ("Dashboard de ResiliÃªncia") para a demo.
* **Zipkin:**
    * DisponÃ­vel para anÃ¡lise de tracing distribuÃ­do de cada chamada (bÃ´nus).

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Backend:** Java 21, Spring Boot 3.4, Spring Retry, OpenFeign
* **Infraestrutura:** Docker & Docker Compose
* **Observabilidade:** Prometheus, Grafana (com provisionamento), Zipkin
* **Testes de Carga:** `hey` (ferramenta de linha de comando)

---

## ğŸ“‹ PrÃ©-requisitos

Para executar este projeto, vocÃª precisarÃ¡ ter instalado:

* Java 21 (ou superior)
* Apache Maven
* Docker e Docker Compose
* [hey](https://github.com/rakyll/hey) (ferramenta de teste de carga)
* Um terminal e seu editor de cÃ³digo favorito

---

## â–¶ï¸ Como Executar

1.  **Clone este repositÃ³rio:**
    ```bash
    git clone <url-do-seu-repositorio>
    cd demo-resiliencia
    ```

2.  **Compile os projetos Java:**
    Ã‰ necessÃ¡rio gerar os arquivos `.jar` que serÃ£o copiados para as imagens Docker.

    ```bash
    # Compile o cliente
    cd resilient-client
    mvn clean package
    cd ..

    # Compile o provider
    cd unreliable-provider
    mvn clean package
    cd ..
    ```

3.  **Suba toda a stack com Docker Compose:**
    Este comando irÃ¡ construir as imagens, criar as redes e iniciar todos os 5 contÃªineres.

    ```bash
    docker-compose up --build -d
    ```

4.  **Verifique se tudo estÃ¡ no ar:**
    * **Grafana:** `http://localhost:3000` (O dashboard jÃ¡ estarÃ¡ lÃ¡!)
    * **Prometheus:** `http://localhost:9090`
    * **Zipkin:** `http://localhost:9411`
    * **API do Client:** `http://localhost:8080/health`
    * **API do Provider:** `http://localhost:8081/control/healthy` (Teste)

---

## ğŸ¤ Roteiro da DemonstraÃ§Ã£o (Runbook)

Este Ã© o guia passo a passo para executar a apresentaÃ§Ã£o. Tenha o Dashboard do Grafana e um terminal lado a lado.

### Setup Inicial

1.  Abra o Grafana no seu navegador: `http://localhost:3000`.
2.  Abra o dashboard "Dashboard de ResiliÃªncia".
3.  Defina o *refresh* do Grafana para **5 segundos** (canto superior direito).
4.  Resete o estado do provider para garantir que ele esteja saudÃ¡vel:
    ```bash
    curl -X POST "http://localhost:8081/control/healthy"
    ```

### CenÃ¡rio 1: ExaustÃ£o de Threads (O Problema)

* **Objetivo:** Mostrar que, sem um timeout curto, requisiÃ§Ãµes lentas podem travar toda a aplicaÃ§Ã£o.
* **GrÃ¡fico no Grafana:** "CenÃ¡rio 1: ExaustÃ£o de Threads (resilient-client)"

1.  **Preparar (Provider):** Configure o `provider` para ter 5 segundos de lentidÃ£o.
    ```bash
    curl -X POST "http://localhost:8081/control/slow?delay=5000"
    ```

2.  **Executar (Client):** Simule 15 usuÃ¡rios simultÃ¢neos chamando o endpoint com **timeout longo** (30s).
    ```bash
    hey -c 15 -n 15 "http://localhost:8080/demo/timeout?strategy=long"
    ```

3.  **Observar (Enquanto o `hey` roda):**
    * **Grafana:** O grÃ¡fico `tomcat_threads_busy` subirÃ¡ e **cravarÃ¡ em 10**.
    * **Terminal:** Tente acessar o endpoint de health. Ele ficarÃ¡ travado!
        ```bash
        curl http://localhost:8080/health
        ```
    * **LiÃ§Ã£o:** Todas as 10 threads do Tomcat estÃ£o presas esperando o `provider`. A aplicaÃ§Ã£o estÃ¡ morta.

### CenÃ¡rio 2: PadrÃ£o Timeout (A SoluÃ§Ã£o)

* **Objetivo:** Mostrar como o "Fail Fast" (timeout curto) salva a aplicaÃ§Ã£o.
* **GrÃ¡fico no Grafana:** "CenÃ¡rio 1: ExaustÃ£o de Threads (resilient-client)"

1.  **Preparar (Provider):** (NÃ£o precisa, ele jÃ¡ estÃ¡ lento).

2.  **Executar (Client):** Rode o *mesmo* teste, mas agora no endpoint com **timeout curto** (2s).
    ```bash
    hey -c 15 -n 15 "http://localhost:8080/demo/timeout?strategy=short"
    ```

3.  **Observar:**
    * **Grafana:** O grÃ¡fico `tomcat_threads_busy` darÃ¡ um pico rÃ¡pido e **cairÃ¡ para 0** imediatamente.
    * **Terminal:** Tente acessar o endpoint de health. Ele responde na hora!
        ```bash
        curl http://localhost:8080/health
        ```
    * **LiÃ§Ã£o:** Ã‰ melhor falhar rÃ¡pido (Fail Fast) para 15 usuÃ¡rios do que travar a aplicaÃ§Ã£o para *todos* os usuÃ¡rios.

### CenÃ¡rio 3: Retry Storm (O Problema)

* **Objetivo:** Mostrar o perigo de retentativas ingÃªnuas (sem backoff), que podem amplificar a falha.
* **GrÃ¡fico no Grafana:** "CenÃ¡rio 2: Carga no Provider (Retries)"

1.  **Preparar (Provider):** Configure o `provider` para falhar nas 2 primeiras tentativas.
    ```bash
    curl -X POST "http://localhost:8081/control/flaky?count=2"
    ```

2.  **Executar (Client):** Simule 10 usuÃ¡rios chamando o endpoint com **retry simples**.
    ```bash
    hey -c 10 -n 10 "http://localhost:8080/demo/retry?strategy=simple"
    ```

3.  **Observar:**
    * **Grafana:** O teste dispara 10 requisiÃ§Ãµes. Como cada uma tenta 3 vezes (1 original + 2 retries), o grÃ¡fico do *provider* mostrarÃ¡ um pico de **30 req/s**.
    * **LiÃ§Ã£o:** Amplificamos a carga no `provider` em 3x, criando uma "Tempestade de Retries" (Retry Storm) e piorando a situaÃ§Ã£o.

### CenÃ¡rio 4: Retry com Exponential Backoff (A SoluÃ§Ã£o)

* **Objetivo:** Mostrar como o backoff "dÃ¡ um tempo" para o serviÃ§o se recuperar.
* **GrÃ¡fico no Grafana:** "CenÃ¡rio 2: Carga no Provider (Retries)"

1.  **Preparar (Provider):** (JÃ¡ estÃ¡ configurado para falhar 2x).

2.  **Executar (Client):** Rode o teste no endpoint com **backoff exponencial**.
    ```bash
    hey -c 10 -n 10 "http://localhost:8080/demo/retry?strategy=backoff"
    ```

3.  **Observar:**
    * **Grafana:** O grÃ¡fico nÃ£o serÃ¡ um pico Ãºnico. Ele mostrarÃ¡ **"degraus"** visuais: um pico de 10 req/s (1Âª tentativa), uma pausa, outro pico (2Âª tentativa apÃ³s 1s), outra pausa, e o pico final (3Âª tentativa apÃ³s 2s).
    * **LiÃ§Ã£o:** A carga foi distribuÃ­da ao longo do tempo, dando ao `provider` a chance de se recuperar.

### CenÃ¡rio 5: Backoff + Jitter (O Refinamento)

* **Objetivo:** Explicar o Jitter para evitar o "Thundering Herd" (manada) de retentativas sincronizadas.
* **GrÃ¡fico no Grafana:** "CenÃ¡rio 2: Carga no Provider (Retries)"

1.  **Preparar (Provider):** (JÃ¡ estÃ¡ configurado).

2.  **Executar (Client):** Rode o teste no endpoint com **backoff + jitter**.
    ```bash
    hey -c 10 -n 10 "http://localhost:8080/demo/retry?strategy=jitter"
    ```

3.  **Observar:**
    * **Grafana:** O grÃ¡fico serÃ¡ similar ao do Backoff, mas os "degraus" nÃ£o serÃ£o picos perfeitos. Eles serÃ£o mais "espalhados" e "suavizados".
    * **LiÃ§Ã£o:** O Jitter adiciona aleatoriedade, evitando que todos os clientes tentem novamente *exatamente* no mesmo segundo. Isso "espalha" a carga de forma ainda mais eficaz.

---

## ğŸ§¹ Limpando o Ambiente

ApÃ³s a demonstraÃ§Ã£o, para parar e remover todos os contÃªineres, redes e volumes, execute:

```bash
docker-compose down -v
````

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ grafana/                # Configs de provisionamento do Grafana
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â””â”€â”€ resilience-demo.json
â”‚   â”‚   â””â”€â”€ provisioning/
â”‚   â”‚       â”œâ”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ datasources/
â”‚   â””â”€â”€ prometheus.yml          # Config de scrape do Prometheus
â”œâ”€â”€ docker-compose.yml          # Orquestrador principal
â”œâ”€â”€ client/                     # Projeto Spring (O HerÃ³i)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pom.xml
â””â”€â”€ api/                        # Projeto Spring (O VilÃ£o)
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ pom.xml
```